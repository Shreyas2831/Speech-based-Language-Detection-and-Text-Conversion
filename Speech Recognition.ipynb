{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1565ea80",
   "metadata": {},
   "source": [
    "# Speech based Language Detection and Text Conversion \n",
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e05126f",
   "metadata": {},
   "source": [
    "## Package Installation and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import Dash, html, dcc, dash_table\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_bootstrap_components as dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import json\n",
    "import speech_recognition as sr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import fasttext\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d746e",
   "metadata": {},
   "source": [
    "## Azure Key creation and usage. Key will not be shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0774ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_key, service_region = \"********************************\", \"eastus\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3ac15f",
   "metadata": {},
   "source": [
    "## Training sample csv. Created from IEEE dataset provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba534ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:\\Shreyas\\Speech Language Recognition\\Data_Dictionary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72cad9d",
   "metadata": {},
   "source": [
    "## Speech Recognition Visual Component declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e56e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d5ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_button_style = {'background-color': 'white',\n",
    "                      'color': 'black',\n",
    "                      'height': '30px',\n",
    "                      'width': '100px',\n",
    "                      'margin-top': '5px',\n",
    "                      'margin-left': '100px', \n",
    "                      'margin-bottom': '20px',\n",
    "                        'border-radius': '30px'}\n",
    "\n",
    "text_style = {'background-color': 'white', \n",
    "              'height': '30px', \n",
    "              'width': '100px', \n",
    "              'margin-top': '10px',\n",
    "              'marginRight':'10px',\n",
    "              'margin-bottom': '20px'\n",
    "                 }\n",
    "\n",
    "text_box_style = {'background-color': 'white', \n",
    "                  'height': '30px', \n",
    "                  'width': '100px', \n",
    "                  'margin-top': '5px',\n",
    "                  'marginRight':'10px',\n",
    "                  'margin-bottom': '20px'\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c2387",
   "metadata": {},
   "outputs": [],
   "source": [
    "leftside_col = dbc.Col([\n",
    "    html.H3('Fasttext Model Prediction'), \n",
    "    html.H4('Pretrained Model'),\n",
    "    html.Label('Predicted Language'),\n",
    "    dcc.Input(id='fasttext_model', value='MTL', type='text', style={'background-color': 'white', 'marginLeft':'10px', 'height': '30px', 'width': '400px'}),\n",
    "], className='column_left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rightside_col = dbc.Col([\n",
    "    html.H3('MultimomialDb Model Prediction'),\n",
    "    html.H4('Model Trained By Dataset Given From IEEE'),\n",
    "    html.Label('Predicted Language'),\n",
    "    dcc.Input(id='binomialdb_predict', value='MTL', type='text', style={'background-color': 'white', 'marginLeft':'10px', 'height': '30px'})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = html.Div([html.Div([\n",
    "    html.H1('SPEECH LANGUAGE RECOGNITION', style={'text-align':'center', 'font-family':'Algerian', 'color':'#7FDBFF'}),\n",
    "    \n",
    "    html.Br(),\n",
    "    \n",
    "    html.Label('Time', style={\"font-weight\": \"bold\"}),\n",
    "    html.Br(),\n",
    "    dcc.Input(id='my-input', placeholder='Time in sec..', type='text', style = text_box_style),\n",
    "\n",
    "    html.Button(id='button',\n",
    "                children=['Start Recording'],\n",
    "                n_clicks=1,\n",
    "                style=white_button_style\n",
    "    ),\n",
    "    html.Button(id='button1',\n",
    "                children=['Detect'],\n",
    "                n_clicks=1,\n",
    "                style=white_button_style\n",
    "    ),\n",
    "    \n",
    "    html.Hr(),\n",
    "    \n",
    "    html.H3('Speech Language Detected'),\n",
    "    \n",
    "    html.Label('Predicted Language'),\n",
    "    dcc.Input(id= 'predicted_lang', value='Detected_Language', type='text', style={'background-color': 'white', 'marginLeft':'10px', 'height': '30px'}),\n",
    "    \n",
    "    html.Br(),\n",
    "    \n",
    "    html.Hr(),\n",
    "    \n",
    "    html.H3('Spoken Text'),\n",
    "    \n",
    "    #html.Label('Text'),\n",
    "    dcc.Input(id= 'spoken_text', value='MTL', type='text', style={'background-color': 'white', 'marginLeft':'10px', 'height': '30px', 'width': '1000px'}),\n",
    "    \n",
    "    html.Br(),\n",
    "    \n",
    "    html.Hr(),\n",
    "    \n",
    "    dbc.Row([\n",
    "        leftside_col,\n",
    "\n",
    "        rightside_col    \n",
    "    ]),\n",
    "    \n",
    "    html.Hr(),\n",
    "    \n",
    "    \n",
    "    \n",
    "    #html.Div(id='content2'),\n",
    "    html.H3('Convert Text In'),\n",
    "    \n",
    "    dcc.Dropdown(id='symbol-dropdown',\n",
    "        options={\n",
    "            'en': 'English',\n",
    "            'es':'Spanish' ,\n",
    "            'hi': 'Hindi',\n",
    "            'ta': 'Tamil',\n",
    "            'te': 'Telugu',\n",
    "            'kn': 'Kannada',\n",
    "            'ml': 'Malyalam',\n",
    "            'gu': 'Gujurati',\n",
    "            'bn': 'Bengali'\n",
    "   },\n",
    "        value='English', style = {'color': 'black'}\n",
    "    ),\n",
    "    \n",
    "    html.Br(),\n",
    "    \n",
    "    html.Button(id='button2',\n",
    "                children=['Convert'],\n",
    "                n_clicks=1,\n",
    "                style=white_button_style\n",
    "    ),\n",
    "    html.Br(),\n",
    "       \n",
    "    html.Label('Converted Text'),\n",
    "    dcc.Input(id='converted_text', value='MTL', type='text', style={'background-color': 'white', 'marginLeft':'10px', 'height': '30px', 'width': '1000px'}),\n",
    "    \n",
    "    html.Div(id='my-output'),\n",
    "    \n",
    "    html.Br()\n",
    "    \n",
    "], style={'margin-left': '5%', 'margin-right': '5%', 'margin-top': '30px'})],style={'background-color': '#5a5a5a','margin-top': '0px',\n",
    "                    'color': 'white'} )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8442ecc1",
   "metadata": {},
   "source": [
    "## Speech Recording on \"Start Recording\" Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eea406",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(Output('button', 'style'), [Input('button', 'n_clicks')],\n",
    "              [Input('my-input', 'value')])\n",
    "def change_button_style(n_clicks, value):\n",
    "    chunk = 1024  # Record in chunks of 1024 samples\n",
    "    SampleFormat = pyaudio.paInt16  # 16 bits per sample\n",
    "    channels = 2\n",
    "    fs = 44100  # Record at 44100 samples per second\n",
    "    seconds = int(value)\n",
    "    \n",
    "    filename = \"output_dash.wav\"\n",
    "\n",
    "    port = pyaudio.PyAudio()  # Create an interface to PortAudio\n",
    "\n",
    "    port_stream = port.open(format=SampleFormat,\n",
    "                    channels=channels,\n",
    "                    rate=fs,\n",
    "                    frames_per_buffer=chunk,\n",
    "                    input=True)\n",
    "\n",
    "    array_frames = []  # Initialize array to store frames\n",
    "\n",
    "    # Store data in chunks for 3 seconds\n",
    "    for i in range(0, int(fs / chunk * seconds)):\n",
    "        data = port_stream.read(chunk)\n",
    "        array_frames.append(data)\n",
    "\n",
    "    # Stop and close the stream \n",
    "    port_stream.stop_stream()\n",
    "    port_stream.close()\n",
    "    # Terminate the PortAudio interface\n",
    "    port.terminate()\n",
    "\n",
    "    print('Finished recording')\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    wavf = wave.open(filename, 'wb')\n",
    "    wavf.setnchannels(channels)\n",
    "    wavf.setsampwidth(port.get_sample_size(SampleFormat))\n",
    "    wavf.setframerate(fs)\n",
    "    wavf.writeframes(b''.join(array_frames))\n",
    "    wavf.close()\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_file = \"output_dash.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950db5be",
   "metadata": {},
   "source": [
    "## Speech to Text Conversion using Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770afc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(DL):\n",
    "    recog = sr.Recognizer()\n",
    "    #lang = \n",
    "    file_det = sr.AudioFile(wav_file)\n",
    "    with file_det as source:\n",
    "        file_det = recog.record(source)\n",
    "    text = recog.recognize_google(file_det, language = DL)\n",
    "    print(\"Recognized Text: \" + text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f5008",
   "metadata": {},
   "source": [
    "## Speech to Text Detection using trained dataset converted from IEEE Dataset \n",
    "Referance Link: https://ieeespsgs.org/mspcup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62326932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimonialdb_model_predict(text):\n",
    "    dataset = pd.read_csv(\"D:\\Shreyas\\Speech Language Recognition\\Data_Dictionary.csv\")\n",
    "\n",
    "    x = np.array(dataset[\"Statement\"])\n",
    "    y = np.array(dataset[\"Language\"])\n",
    "\n",
    "    cv = CountVectorizer()\n",
    "    X = cv.fit_transform(x)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=0.33, \n",
    "                                                        random_state=42)\n",
    "\n",
    "    multinomial_model = MultinomialNB()\n",
    "    multinomial_model.fit(X_train,y_train)\n",
    "    multinomial_model.score(X_test,y_test)\n",
    "\n",
    "    text_data = cv.transform([text]).toarray()\n",
    "    lang_output = multinomial_model.predict(text_data)\n",
    "   \n",
    "    return lang_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d858732d",
   "metadata": {},
   "source": [
    "## Speech to Text Detection using pre-trained dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e799e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_model_prediction(text):\n",
    "    pretrained_lang_model = \"F:\\Shreyas Gonjari\\Downloads\\lid.176.bin\"\n",
    "    fasttext_model = fasttext.load_model(pretrained_lang_model)\n",
    "    predictions = fasttext_model.predict(text, k=1) # returns top 2 matching languages\n",
    "    #print(predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e7f38",
   "metadata": {},
   "source": [
    "## Speech Language detection using Azure Speech API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae593a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(Output('predicted_lang', 'value'), Output('spoken_text', 'value'), Output('fasttext_model', 'value'), \n",
    "              Output('binomialdb_predict', 'value'), [Input('button1', 'n_clicks')])\n",
    "def language_detection_of_speech(n_clicks):\n",
    "    # Creates an AutoDetectSourceLanguageConfig, which defines a number of possible spoken languages\n",
    "    spoken_lang_config = speechsdk.languageconfig.AutoDetectSourceLanguageConfig(languages=[\"es-ES\", \"en-US\", \"mr-IN\", \"hi-IN\"])\n",
    "\n",
    "    speech_conf = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    speech_conf.set_property(property_id=speechsdk.PropertyId.SpeechServiceConnection_SingleLanguageIdPriority, value='Latency')\n",
    "    \n",
    "    audio_conf = speechsdk.audio.AudioConfig(filename = wav_file)\n",
    "    \n",
    "    source_language_recognizer = speechsdk.SourceLanguageRecognizer(speech_config=speech_conf,\n",
    "                                                                    auto_detect_source_language_config=spoken_lang_config,\n",
    "                                                                    audio_config=audio_conf)\n",
    "\n",
    "\n",
    "    result = source_language_recognizer.recognize_once()\n",
    "\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        detected_src_lang = result.properties[\n",
    "            speechsdk.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult]\n",
    "        Detected_Language = \"{}\".format(detected_src_lang)\n",
    "        print(\"Detected Language: \" + Detected_Language)\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Language Detection canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            \n",
    "    #Mapping of Language shrt form and Original Language\n",
    "    df = pd.read_csv('code.csv')\n",
    "    filter_df = df[df['Lang_code'].str.lower().str.contains(Detected_Language)]\n",
    "    filter_df = filter_df.reset_index()\n",
    "    displaylang = filter_df['Display_Lang'][0]\n",
    "            \n",
    "    text = speech_to_text(Detected_Language)\n",
    "    predict_multimonialdb = multimonialdb_model_predict(text)\n",
    "    predict_fasttext = fasttext_model_prediction(text)\n",
    "    print(predict_fasttext)\n",
    "\n",
    "    return displaylang, text, str(predict_fasttext), str(predict_multimonialdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad5126",
   "metadata": {},
   "source": [
    "## Language translation using Google Translator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e763ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('converted_text', 'value'),\n",
    "    [Input('button2', 'n_clicks')],\n",
    "    [Input('spoken_text', 'value')],\n",
    "    State('symbol-dropdown', 'value')\n",
    ")\n",
    "def convert_text(n_clicks, text, symbol):\n",
    "    translator = Translator()\n",
    "    \n",
    "    translated_text = translator.translate(text, dest=symbol)\n",
    "    converted_text = translated_text.text\n",
    "    \n",
    "    return converted_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b693f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9b0a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
